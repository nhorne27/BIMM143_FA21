---
title: "Mini-Project"
author: 'Natasha ( PID: A15393874)'
date: "10/23/2021"
output: pdf_document
---

```{r}
#save the data as a variable
data <- "WisconsinCancer.csv"
#inputting data and ensuring column names are set correctly
wisc.df <- read.csv(data, row.names = 1)
View(wisc.df)
```
```{r}
# We can use -1 here to remove the first column
wisc.data <- wisc.df[,-1]
# Create diagnosis vector for later 
diagnosis <- as.factor(wisc.df$diagnosis) 
diagnosis
```
> Q1. How many observations are in this dataset?

```{r}
nrow(wisc.data)
```
A1. 569
> Q2. How many of the observations have a malignant diagnosis?

```{r}
#table() outputs a contingency table of displaying the amount of repeated inputs
table(diagnosis)
```

A2. 212 malignant diagnosis
> Q3. How many variables/features in the data are suffixed with _mean?

```{r}
#grep() finds specific matches to the argument pattern in each element of character vectors
#This outputs which columns have the suffix"_mean"
mean <- grep("_mean", colnames(wisc.df))
length(mean)

```
A3. 10 variables

```{r}
# Check column means and standard deviations
colMeans(wisc.data)


```
```{r}
apply(wisc.data,2,sd)
```
#We need to use scale=TRUE in this case for the PCA analysis as the columns data are on different scales

```{r}
# Perform PCA on wisc.data by completing the following code
wisc.pr <- prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
```
> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

#0.4427 or 44.27%

> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

# 3 principal components needed to describe at least 70% of the original variance in the data.

> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

#7 principal components needed to describe at least 90% of the original variance in the data

#Interpretting PCA Results
We will create a some visualizations to help understand the PCA results. We will create a biplot.

```{r}
biplot(wisc.pr)

```

> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?
It is is a mess to me of data with a black mark in the center. It is not easy to interpret because I do not know what the numbering on the sides stand for/represent. 

```{r}
# Scatter plot observations by components 1 and 2
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=as.factor(diagnosis), xlab = "PC1",
ylab ="PC2")
```
> Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

```{r}
# Scatter plot observations by components 1 and 3
plot(wisc.pr$x[,1], wisc.pr$x[,3], col=as.factor(diagnosis), xlab = "PC1",
ylab ="PC3")

```
# There is more variance for PC2 in the original data than PC3. The plot before this one is better from separating the samples of malignant and benign.P1 and P3 have less variance and so there is less variation and they are squished together.

```{r}
# Create a data.frame for ggplot
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis
# Load the ggplot2 package
library(ggplot2)
# Make a scatter plot colored by diagnosis
ggplot(df) +
aes(PC1, PC2, col=diagnosis) +
geom_point()

```
#We will produce scree plots showing the proportion of variance explained as the number of PCs increases.
#First, we calculate the variance of each PC by squaring the sdev component of wisc.pr
```{r}

# Calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)

```
#Then, we calculate the variance explained by each PC by dividing by the total variance explained of all PCs.
```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

```

```{r}
# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component",
ylab = "Proportion of Variance Explained",
ylim = c(0, 1), type = "o")

```

```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

#We will check our understanding of the PCA results like the loadings and variance explained.

> Q9. For the first principal component, what is the component of the loading vector
(i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
wisc.pr$rotation["concave.points_mean", 1]

```
#The component for concave.points_mean is -0.2608538.

> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

```{r}
summary(wisc.pr)

```

# Utilizing the data provided by summary() we would need to use at least 4 PCS to explain 80% of the data.

#The distance between all pairs of observations are computed.
```{r}

# Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)

```

#Calculate the distance between all pairs in the new scaled dataset

```{r}
data.dist <- dist(data.scaled)
```

# Create a hierarchical clustering model using complete linkage.
```{r}
wisc.hclust <- hclust(data.dist)

```

> Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

```{r}
# Viewing the plot
plot(wisc.hclust)
#adding a line to view height at which 4 clusters are made
abline(h=19, col="red", lty=2)


```

# The average height is 19 where there are 4 clusters.

#We will compare the outputs from your hierarchical clustering model to the actual diagnoses.
```{r}
#using cutree to cut the tree to make 4 clusters
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
#use table() function to compare the cluster membership to the actual diagnoses
table(wisc.hclust.clusters, diagnosis)
```

> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

```{r}
wisc.hclust.clusters2 <- cutree(wisc.hclust, k=2)
table(wisc.hclust.clusters2, diagnosis)

```

```{r}
wisc.hclust.clusters3 <- cutree(wisc.hclust, k=3)
table(wisc.hclust.clusters3, diagnosis)
```

```{r}
wisc.hclust.clusters5 <- cutree(wisc.hclust, k=4)
table(wisc.hclust.clusters5, diagnosis)
```
```{r}
wisc.hclust.clusters5 <- cutree(wisc.hclust, k=5)
table(wisc.hclust.clusters5, diagnosis)
```

```{r}
wisc.hclust.clusters6 <- cutree(wisc.hclust, k=6)
table(wisc.hclust.clusters6, diagnosis)

```

```{r}
wisc.hclust.clusters7 <- cutree(wisc.hclust, k=7)
table(wisc.hclust.clusters7, diagnosis)
```

```{r}
wisc.hclust.clusters8 <- cutree(wisc.hclust, k=8)
table(wisc.hclust.clusters8, diagnosis)
```
```{r}
wisc.hclust.clusters8 <- cutree(wisc.hclust, k=9)
table(wisc.hclust.clusters8, diagnosis)
```

```{r}
wisc.hclust.clusters8 <- cutree(wisc.hclust, k=10)
table(wisc.hclust.clusters8, diagnosis)
```

# I would say 2-6 as a lower number seems to be better for number of clusters.
> Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

```{r}
# single method
wisc.hclust.single <- hclust(data.dist, method= "single" )
plot(wisc.hclust.single)
```

```{r}
# Complete method
wisc.hclust.complete <- hclust(data.dist, method= "complete" )
plot(wisc.hclust.complete)

```
```{r}
# Average method
wisc.hclust.average <- hclust(data.dist, method= "average" )
plot(wisc.hclust.average)

```

```{r}
# Ward.D2 method
wisc.hclust.ward.D2 <- hclust(data.dist, method= "ward.D2" )
plot(wisc.hclust.ward.D2)

```

# None of them are super clean or efficient, but out of the options D2 is probably the best for cleanliness and it is also most similar in appearance. 

#We will create a k-means clustering model on the data and compare the results to the actual diagnoses and results of the hierarchical clustering model.

```{r}
#creating k-means with the scaled data created for the hierarchical clustering
#Making 2 clusters and running algorithm 20 times
wisc.km <- kmeans(data.scaled, centers=2, nstart= 20)

#use table() function to compare the cluster membership of the k-means model to the actual diagnoses contained in the diagnosis vector.
table(wisc.km$cluster, diagnosis)

```

> Q14. How well does k-means separate the two diagnoses? How does it compare to your hclust results?
Hclust is more accurate than k-means and both do a good job with two clusters.

```{r}
table(wisc.km$cluster, wisc.hclust.clusters)
```

```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:7]), method="ward.D2")
plot(wisc.pr.hclust)

```

```{r}
#creating 2 clusters and a table to view what samples are in each cluster
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)

```

```{r}
#seeing if the 2 branches represent M and B samples
table(grps, diagnosis)
```

```{r}
#plotting the results using grps to color
plot(wisc.pr$x[,1:2], col=grps)
```

```{r}
#plotting the results using diagnosis vector to color
plot(wisc.pr$x[,1:2], col=as.factor(diagnosis))

```

# To match things, we can turn our groups into a factor and reorder the levels so cluster 2 comes first and gets
the first color (black) and cluster 1 gets the second color (red).

```{r}
g <- as.factor(grps)
levels(g)

```

```{r}
g <- relevel(g,2)
levels(g)
```

```{r}
# Plot using our re-ordered factor
plot(wisc.pr$x[,1:2], col=g)
```

```{r}
#Use the distance along the first 7 PCs for clustering
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:7]), method="ward.D2")
#cut 2 clusters
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
```


```{r}
# Compare to actual diagnoses
table(wisc.pr.hclust.clusters, diagnosis)
```

> Q15. How well does the newly created model with four clusters separate out the two diagnoses?
They are separated well in to 4 different clusters with the diagnoses. Cluster 1 has 28 benighn and 188 malignant. Cluster 2 has 329 benign and 24 malignant. Cluster 1 has more malignant than Cluster 2.

> Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

```{r}
table(wisc.km$cluster, diagnosis)
```

```{r}
table(wisc.hclust.clusters, diagnosis)
```

```{r}
#relooking at what the actual amount of M and B samples exist
table(diagnosis)

```

# Both hierarchial and k-means do well in terms of significantly separating M and B. Going back to the actual diagnosis, k-means would be considered the most similar to its separation.

> Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

# Hclust has the best specificity and kmeans has the best sensitivity.

# We will use the predict() function that will take our PCA model from the breat cancer dataset and new cancer cell data and project that data
```{r}
#first we need to import the new data
new <- read.csv("new_samples.csv")
#predicting the data
npc <- predict(wisc.pr, newdata=new)
npc

```

# Creating a new plot to compare the prediction
```{r}
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

> Q18. Which of these new patients should we prioritize for follow up based on your results?

#Person 1